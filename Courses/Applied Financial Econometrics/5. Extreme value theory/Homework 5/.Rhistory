cycle <- hpfilter(hp.trend$cycle,type="lambda",freq=NULL)$trend
plot(cycle)
library(forecast)
install.packages("forecast")
library(forecast)
accuracy(cycle)
accuracy(as.zoo(cycle))
forecast(cycle)
forecast(cycle,5)
xforecast(cycle,5)
x = forecast(cycle,5)
plot(x)
x = forecast(cycle,63)
plot(x)
x = HoltWinters(cycle)
x
plot(x)
?HoltWinters
arima
x = arima(cycle)
x
plot(x)
xx = forecast(x, 63)
plot(xx)
x = autio.arima(cycle)
x = auto.arima(cycle)
x
xx = forecast(x, 63)
plot(xx)
x = ets(cycle)
plot(x)
xx = forecast(x,63)
plot(x)
plot(xx)
cycle <- hpfilter(hp.trend$cycle,type="lambda",freq=1600)$trend
plot(cycle)
fit = auto.arima(cycle)
source('~/CMF/Courses/Machine Learning/2. Time series decomposition, seasonal, trend & cycle/Homework 2/ML_HM2.R', echo=TRUE)
plot(pred)
fit = auto.arima(cycle)
pred = forecast(fit)
plot(pred)
fit = ets(cycle)
plot(fit)
pred = forecast(fit)
plot(pred)
pred
## repeat H-P for smoother cycle
cycle <- hpfilter(hp.trend$cycle,type="lambda",freq=1600)$trend
plot(cycle)
cycle <- hpfilter(hp.trend$cycle,type="lambda",freq=1600)$trend
plot(cycle)
fit = auto.arima(cycle)
pred = forecast(fit)
plot(pred)
pred = forecast(fit,63)
plot(pred)
cycle
pred
pred[,1]
str$pred
str(pred)
pred$mean
cycle
c(cycle,pred$mean)
merge(cycle,pred$mean)
pred
str(pred)
x = plot(pred)
x
x = c(cycle,pred$mean)
x
x <- ts(x, start = c(1959, 8), freq = 12)
x
plot(x)
plot(x)
x
par(mfrow=c(1,1))
plot(x)
str(stl.y)
str.y
stl.y
str(y.stl)
str(stl.y)
stl.y$time.series
ts = stl.y$time.series
ts
ts[,1]
ts
head(ts)
ts[,1]
fit = auto.arima(ts[,1])
pred = forecast(fit,63)
plot(pred)
ts[,1]
forecast(ts[,1])
xforecast(ts[,1])
x=forecast(ts[,1])
plot(x)
pred = forecast(ts[,1],63)
plot(pred)
res.season = c(cycle,pred$mean)
res.season <- ts(res.season, start = c(1959, 8), freq = 12)
plot(res.season)
pred = forecast(ts[,1],63)
plot(pred)
res.season = c(ts[,1],pred$mean)
res.season <- ts(res.season, start = c(1959, 8), freq = 12)
plot(res.season)
head(ts)
head(ts[,2])
plot(forecast(ts[,2]))
## predict cycle
pred = forecast(ts[,2],63)
plot(pred)
res.trend = c(ts[,2],pred$mean)
res.trend <- ts(res.trend, start = c(1959, 8), freq = 12)
plot(res.trend)
result = res.trend + res.season + res.cycle
fit = auto.arima(cycle)
pred = forecast(fit,63)
plot(pred)
res.cycle = c(cycle,pred$mean)
res.cycle <- ts(res.cycle, start = c(1959, 8), freq = 12)
result = res.trend + res.season + res.cycle
result
plot(resutl)
plot(result)
plot(exp(result))
fit = auto.arima(cycle)
pred = forecast(fit,63)
fit = auto.arima(cycle)
pred.cycle = forecast(fit,63)
plot(pred.cycle)
res.cycle = c(cycle,pred.cycle$mean)
res.cycle <- ts(res.cycle, start = c(1959, 8), freq = 12)
plot(res.cycle)
pred = forecast(ts[,1],63)
plot(pred)
res.season = c(ts[,1],pred$mean)
res.season <- ts(res.season, start = c(1959, 8), freq = 12)
plot(res.season)
result = res.trend + res.season + res.cycle
plot(exp(result))
result.pred = pred.cycle$mean + pred.season$mean + pred.trend$mean
fit = auto.arima(cycle)
pred.cycle = forecast(fit,63)
plot(pred.cycle)
res.cycle <- ts(res.cycle, start = c(1959, 8), freq = 12)
## predict seasonal component
pred.season = forecast(ts[,1],63)
plot(pred.season)
res.season <- ts(res.season, start = c(1959, 8), freq = 12)
## predict cycle
pred.trend = forecast(ts[,2],63)
plot(pred.trend)
res.trend <- ts(res.trend, start = c(1959, 8), freq = 12)
result.pred = pred.cycle$mean + pred.season$mean + pred.trend$mean
result.pred = exp(result.pred)
plot(result.pred)
y = exp(y)
##### Time series decompostion #####
plot(y)
## decompose ts into trend, seasonal and remainder data
stl.y <- stl(y, s.window="periodic", robust=FALSE)
plot(stl.y)
## separate trend from cycles
# lambda = 6.25 for yearly data
# lambda = 1600 for quarterly data
# lambda = 129600 for monthly data
# freq = NULL to choose lambda automatically
hp.trend <- hpfilter(stl.y$time.series[,"trend"], type = "lambda", freq = 129600, drift = FALSE)
plot(hp.trend)
## repeat H-P for smoother cycle
cycle <- hpfilter(hp.trend$cycle,type="lambda",freq=1600)$trend
plot(cycle)
##### Predict new values for the series decompositions #####
## use ARIMA to predict cycle
fit = auto.arima(cycle)
pred.cycle = forecast(fit,63)
plot(pred.cycle)
res.cycle <- ts(res.cycle, start = c(1959, 8), freq = 12)
## predict seasonal component
pred.season = forecast(ts[,1],63)
plot(pred.season)
res.season <- ts(res.season, start = c(1959, 8), freq = 12)
## predict cycle
pred.trend = forecast(ts[,2],63)
plot(pred.trend)
res.trend <- ts(res.trend, start = c(1959, 8), freq = 12)
##### Combine decompositions #####
result = res.trend + res.season + res.cycle
result = exp(result)
result.pred = pred.cycle$mean + pred.season$mean + pred.trend$mean
result.pred = exp(result.pred)
plot(result)
?write.csv
write.csv(result.pred, "result.csv")
##### Loading data #####
tmp = read.csv("Data/prod_indx_train.csv", header = TRUE)[,1]
y <- ts(log(tmp), start = c(1959, 8), freq = 12)
##### Time series decompostion #####
plot(y)
## decompose ts into trend, seasonal and remainder data
stl.y <- stl(y, s.window="periodic", robust=FALSE)
plot(stl.y)
## separate trend from cycles
# lambda = 6.25 for yearly data
# lambda = 1600 for quarterly data
# lambda = 129600 for monthly data
# freq = NULL to choose lambda automatically
hp.trend <- hpfilter(stl.y$time.series[,"trend"], type = "lambda", freq = 129600, drift = FALSE)
plot(hp.trend)
## repeat H-P for smoother cycle
cycle <- hpfilter(hp.trend$cycle,type="lambda",freq=1600)$trend
plot(cycle)
##### Predict new values for the series decompositions #####
## use ARIMA to predict cycle
fit = auto.arima(cycle)
pred.cycle = forecast(fit,63)
plot(pred.cycle)
res.cycle <- ts(res.cycle, start = c(1959, 8), freq = 12)
## predict seasonal component
pred.season = forecast(ts[,1],63)
plot(pred.season)
res.season <- ts(res.season, start = c(1959, 8), freq = 12)
## predict cycle
pred.trend = forecast(ts[,2],63)
plot(pred.trend)
res.trend <- ts(res.trend, start = c(1959, 8), freq = 12)
##### Combine decompositions #####
result = res.trend + res.season + res.cycle
result = exp(result)
result.pred = pred.cycle$mean + pred.season$mean + pred.trend$mean
result.pred = exp(result.pred)
write.csv(result.pred, "result.csv")
write.csv(result.pred, "result.csv")
write.csv2(result.pred, "result.csv")
Now we combine all the components and take the exponent of the series in order to get back to the original scale.
setwd("~/CMF/Courses/Applied Financial Econometrics/5. Extreme value theory/Homework 5")
##### Initialisation #####
setwd("~/CMF/Courses/Applied Financial Econometrics/5. Extreme value theory/Homework 5")
library("quantmod")
library("fGarch")
library("zoo")
library("xts")
library("ghyp")
Sys.setlocale("LC_ALL","English")
##### Loading data #####
tickers = c("SPY") # specify the tickers to load
e <- new.env() # environment where data will be stored
options("getSymbols.warning4.0"=FALSE) # suppress warning about future change in the function behaviour
getSymbols(tickers, src = "yahoo", from="2013-01-01", env=e) # load data from Yahoo Finance
data = do.call(merge, eapply(e, Ad)[tickers]) # merge data into a single xts taking only adjusted prices
names(data) = tickers
##### Calculate returns #####
rets = apply(data, 2, function(x) diff(x)/x[-length(x)])
rets = xts(rets, order.by = index(data)[-1])
##### GARCH modelling #####
rets.gfit <- garchFit(formula=~aparch(1,1),data=rets,leverage=TRUE,cond.dist="ged", trace=FALSE)
rets.forecast <- predict(rets.gfit,n.ahead=10^4)
##### VaR and ES calculation
alpha <- 0.05
VaR <- rets.forecast[1,1]+rets.forecast[1,3]*qged(alpha,mean=0,sd=1, nu=rets.gfit@fit$par["shape"])
rets.forecast <- sort(rets.forecast[,1])
ES <- mean(rets.forecast[1:(alpha*10^4-1)])
VaR
ES
##### VaR curve #####
VaR_curve <- numeric()
h <- 0.5*260
for (i in (h+1):length(rets))
{
h.rets <- rets[(i-h):(i-1)]
rets.gfit <- garchFit(formula=~aparch(1,1), data=h.rets, leverage=TRUE, cond.dist="ged", trace=FALSE)
rets.forecast <- predict(rets.gfit,n.ahead=1)
VaR_curve[i-h] <- rets.forecast[1,1]+rets.forecast[1,3]*qged(alpha,mean=0,sd=1, nu=rets.gfit@fit$par["shape"])
}
fact <- rets[(h+1):length(rets)]
plot(as.numeric(fact),type="l", ylab = "Return")
warnings()
VaR_curve
lines(VaR_curve,col="red")
##### Kupiec test #####
K <- sum(fact<VaR_curve); alpha0 <- K/length(rets)
S <- -2*log((1-alpha)^(length(rets)-K)*alpha^K)+
2*log((1-alpha0)^(length(rets)-K)*alpha0^K)
p.value <- 1-pchisq(S,df=1)
p.value
alpha
alpha0
##### VaR curve #####
VaR_curve <- numeric()
h <- 0.5*260
for (i in (h+1):length(rets))
{
h.rets <- rets[(i-h):(i-1)]
#  rets.gfit <- garchFit(formula=~aparch(1,1), data=h.rets, leverage=TRUE, cond.dist="ged", trace=FALSE)
rets.gfit <- garchFit(formula=~aparch(1,1),data=h.rets,
delta=2,include.delta=FALSE,leverage=TRUE,cond.dist="sged",
shape=1.5,include.shape=FALSE,trace=FALSE)
rets.forecast <- predict(rets.gfit,n.ahead=1)
VaR_curve[i-h] <- rets.forecast[1,1]+rets.forecast[1,3]*qged(alpha,mean=0,sd=1, nu=rets.gfit@fit$par["shape"])
}
fact <- rets[(h+1):length(rets)]
plot(as.numeric(fact),type="l", ylab = "Return")
lines(VaR_curve,col="red")
lines(VaR_curve,col="red")
setwd("~/CMF/Courses/Applied Financial Econometrics/5. Extreme value theory/Homework 5")
install.packages("evd")
setwd("~/CMF/Courses/Applied Financial Econometrics/5. Extreme value theory/Homework 5")
library("evd")
Sys.setlocale("LC_ALL","English")
input_data <- read.csv("Data/loss_train.csv")
head(input_data)
total_debt <- rowSums(data)
data <- read.csv("Data/loss_train.csv")
total_debt <- rowSums(data)
total_debt
T <- length(total_debt)
debt <- rowSums(data)
T <- length(debt)
## setting levels
u <- numeric(); alpha <- numeric();
u[1] <- sort(total_debt)[0.99*T]; alpha[1] <- 1-1/1000;
u[2] <- sort(total_debt)[0.95*T]; alpha[2] <- 1-1/1000;
u[3] <- sort(total_debt)[0.90*T]; alpha[3] <- 1-1/1000;
##fit distributions, find parameters
levels <- numeric()
for (i in 1:3)
{
gpd.fit <- fpot(total_debt,threshold=u[i],model="gpd",method="SANN")
beta <- gpd.fit$estimate[1]
xi <- gpd.fit$estimate[2]
Fu <- gpd.fit$pat
levels[i] <- u[i]+beta/xi*(((1-alpha[i])/Fu)^(-xi)-1)
}
levels
##### Loading and processing data #####
data <- read.csv("Data/loss_train.csv")
debt <- rowSums(data)
T <- length(debt)
##### Set debt levels #####
u <- numeric()
alpha = 1-1/1000;
u[1] <- sort(debt)[0.99 * T]
u[2] <- sort(debt)[0.95 * T]
u[3] <- sort(debt)[0.90 * T]
##### Fit GPD and find levels #####
levels <- numeric()
for (i in 1:3)
{
gpd.fit <- fpot(total_debt,threshold=u[i],model="gpd",method="SANN")
beta <- gpd.fit$estimate[1]
xi <- gpd.fit$estimate[2]
Fu <- gpd.fit$pat
levels[i] <- u[i]+beta/xi*(((1-alpha[i])/Fu)^(-xi)-1)
}
##### Loading and processing data #####
data <- read.csv("Data/loss_train.csv")
debt <- rowSums(data)
T <- length(debt)
##### Set debt levels #####
u <- numeric()
alpha = 1-1/1000;
u[1] <- sort(debt)[0.99 * T]
u[2] <- sort(debt)[0.95 * T]
u[3] <- sort(debt)[0.90 * T]
##### Fit GPD and find levels #####
levels <- numeric()
for (i in 1:3)
{
gpd.fit <- fpot(debt,threshold=u[i],model="gpd",method="SANN")
beta <- gpd.fit$estimate[1]
xi <- gpd.fit$estimate[2]
Fu <- gpd.fit$pat
levels[i] <- u[i]+beta/xi*(((1-alpha[i])/Fu)^(-xi)-1)
}
levels
##### Loading and processing data #####
data <- read.csv("Data/loss_train.csv")
debt <- rowSums(data)
T <- length(debt)
##### Set debt levels #####
u <- numeric()
alpha = 1-1/1000;
u[1] <- sort(debt)[0.99 * T]
u[2] <- sort(debt)[0.95 * T]
u[3] <- sort(debt)[0.90 * T]
##### Fit GPD and find levels #####
levels <- numeric()
for (i in 1:3)
{
gpd.fit <- fpot(debt,threshold=u[i],model="gpd",method="SANN")
beta <- gpd.fit$estimate[1]
xi <- gpd.fit$estimate[2]
Fu <- gpd.fit$pat
levels[i] <- u[i]+beta/xi*(((1-alpha[i])/Fu)^(-xi)-1)
}
levels
##### Loading and processing data #####
data <- read.csv("Data/loss_train.csv")
debt <- rowSums(data)
T <- length(debt)
##### Set debt levels #####
u <- numeric()
alpha = 1-1/1000;
u[1] <- sort(debt)[0.99 * T]
u[2] <- sort(debt)[0.95 * T]
u[3] <- sort(debt)[0.90 * T]
##### Fit GPD and find levels #####
levels <- numeric()
for (i in 1:3)
{
gpd.fit <- fpot(debt,threshold=u[i],model="gpd",method="SANN")
beta <- gpd.fit$estimate[1]
xi <- gpd.fit$estimate[2]
Fu <- gpd.fit$pat
levels[i] <- u[i]+beta/xi*(((1-alpha)/Fu)^(-xi)-1)
}
##### Loading and processing data #####
data <- read.csv("Data/loss_train.csv")
debt <- rowSums(data)
T <- length(debt)
##### Set debt levels #####
u <- numeric()
alpha = 1-1/1000;
u[1] <- sort(debt)[0.99 * T]
u[2] <- sort(debt)[0.95 * T]
u[3] <- sort(debt)[0.90 * T]
##### Fit GPD and find levels #####
levels <- numeric()
for (i in 1:3)
{
gpd.fit <- fpot(debt,threshold=u[i],model="gpd",method="SANN")
beta <- gpd.fit$estimate[1]
xi <- gpd.fit$estimate[2]
Fu <- gpd.fit$pat
levels[i] <- u[i]+beta/xi*(((1-alpha)/Fu)^(-xi)-1)
}
levels
##### Initialisation #####
setwd("~/CMF/Courses/Applied Financial Econometrics/5. Extreme value theory/Homework 5")
library("evd")
Sys.setlocale("LC_ALL","English")
##### Loading and processing data #####
data = read.csv("Data/loss_train.csv")
debt = rowSums(data)
T = length(debt)
##### Set debt levels #####
u = numeric()
alpha = 1-1/1000;
u[1] = sort(debt)[0.99 * T]
u[2] = sort(debt)[0.95 * T]
u[3] = sort(debt)[0.90 * T]
##### Fit GPD and find levels #####
result = numeric()
for (i in 1:3)
{
gpd.fit = fpot(debt,threshold=u[i],model="gpd",method="SANN")
beta = gpd.fit$estimate[1]
xi = gpd.fit$estimate[2]
Fu = gpd.fit$pat
result[i] = u[i]+beta/xi*(((1-alpha)/Fu)^(-xi)-1)
}
##### Initialisation #####
setwd("~/CMF/Courses/Applied Financial Econometrics/5. Extreme value theory/Homework 5")
library("evd")
Sys.setlocale("LC_ALL","English")
##### Loading and processing data #####
data = read.csv("Data/loss_train.csv")
debt = rowSums(data)
T = length(debt)
##### Set debt levels #####
u = numeric()
alpha = 1-1/1000;
u[1] = sort(debt)[0.99 * T]
u[2] = sort(debt)[0.95 * T]
u[3] = sort(debt)[0.90 * T]
##### Fit GPD and find levels #####
result = numeric()
for (i in 1:3)
{
gpd.fit = fpot(debt,threshold=u[i],model="gpd",method="SANN")
beta = gpd.fit$estimate[1]
xi = gpd.fit$estimate[2]
Fu = gpd.fit$pat
result[i] = u[i]+beta/xi*(((1-alpha)/Fu)^(-xi)-1)
}
for (i in 1:3)
{
gpd.fit = fpot(debt,threshold=u[i],model="gpd",method="SANN")
beta = gpd.fit$estimate[1]
xi = gpd.fit$estimate[2]
Fu = gpd.fit$pat
result[i] = u[i]+beta/xi*(((1-alpha)/Fu)^(-xi)-1)
}
result
write.csv(result, "result.csv")
m = read.csv("result.csv")
m
-5.61*(-0.0075) + 43.84*0.0075^2
5.61*(-0.0075) + 43.84*0.0075^2
-5.61*(-0.0075) + 43.84*0.0075^2
-5.61*(-0.0075) - 43.84*0.0075^2
-5.61*(-0.0075) + 43.84*0.0075^2
–(10.27)(0.0125) + [(143)(0.0125)2]
(-10.27)(0.0125) + [(143)(0.0125)2]
(-10.27)(0.0125) + (143)(0.0125)2
(-10.27)(0.0125) + (143)(0.0125)^2
(-10.27)(0.0125) + (143)*(0.0125)^2
(-10.27)*(0.0125) + (143)*(0.0125)^2
