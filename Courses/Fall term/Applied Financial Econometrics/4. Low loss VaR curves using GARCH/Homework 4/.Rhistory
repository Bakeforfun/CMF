lines(pred[(k+1):length(pred)], type = "l", col = "red")
summary(lm2)
df.smooth = matrix(ncol = dim(df)[2], nrow = dim(df)[1])
for (i in 1:dim(df)[2]) {
smooth = rollmean(df[, i], k = 20, fill = mean(df[1:20, i]), align = "right")
plot(as.numeric(df[, i]), type = "l")
lines(as.numeric(smooth), type = "l", col = "red")
gap = (df[, i] - smooth)^2
gap = (gap - min(gap))/(max(gap) - min(gap))
df.smooth[, i] = gap
}
df.smooth = as.xts(df.smooth, order.by = date)
names(df.smooth) = names(df)
train = df.smooth["/2013"]
test = df.smooth["2014/"]
k = 5
# x13 = train$X13[1:(dim(train)[1] - k)]
# x16 = train$X16[1:(dim(train)[1] - k)]
# x18 = train$X18[1:(dim(train)[1] - k)]
# x19 = train$X19[1:(dim(train)[1] - k)]
# x39 = train$X39[1:(dim(train)[1] - k)]
# z2 = train$Z2[1:(dim(train)[1] - k)]
# z3 = train$Z3[1:(dim(train)[1] - k)]
# z5 = train$Z5[1:(dim(train)[1] - k)]
# y = train$Y[-1:-k, ]
x13 = as.numeric(train$X13[1:(dim(train)[1] - k)])
x16 = as.numeric(train$X16[1:(dim(train)[1] - k)])
x18 = as.numeric(train$X18[1:(dim(train)[1] - k)])
x19 = as.numeric(train$X19[1:(dim(train)[1] - k)])
x39 = as.numeric(train$X39[1:(dim(train)[1] - k)])
z2 = as.numeric(train$Z2[1:(dim(train)[1] - k)])
z3 = as.numeric(train$Z3[1:(dim(train)[1] - k)])
z5 = as.numeric(train$Z5[1:(dim(train)[1] - k)])
y = as.numeric(train$Y[-1:-5])
lm1 = lm(y ~ x13 + x16 + x18 + x19 + x39 + z2 + z3 + z5)
summary(lm1)
newdata = as.data.frame(coredata((test[,-9])))
names(newdata) = c("x13", "x16", "x18", "x19", "x39", "z2", "z3", "z5")
# newdata = newdata[, c(1,2,3,5,7)]
pred = predict.lm(lm1, newdata = newdata)
plot(as.numeric(test$Y), type = "l")
lines(pred[(k+1):length(pred)], type = "l", col = "red")
summary(test)
test$X14
setwd("~/Systemic risk")
df = read.csv2("new/long.csv")
date = strptime(df$Date, format = "%d.%m.%y")
df = xts(df[,-1], order.by = date)
train = df["/2013"]
test = df["2014/"]
k = 5
# x13 = train$X13[1:(dim(train)[1] - k)]
# x16 = train$X16[1:(dim(train)[1] - k)]
# x18 = train$X18[1:(dim(train)[1] - k)]
# x19 = train$X19[1:(dim(train)[1] - k)]
# x39 = train$X39[1:(dim(train)[1] - k)]
# z2 = train$Z2[1:(dim(train)[1] - k)]
# z3 = train$Z3[1:(dim(train)[1] - k)]
# z5 = train$Z5[1:(dim(train)[1] - k)]
# y = train$Y[-1:-k, ]
x13 = as.numeric(train$X13[1:(dim(train)[1] - k)])
x16 = as.numeric(train$X16[1:(dim(train)[1] - k)])
x18 = as.numeric(train$X18[1:(dim(train)[1] - k)])
x19 = as.numeric(train$X19[1:(dim(train)[1] - k)])
x39 = as.numeric(train$X39[1:(dim(train)[1] - k)])
z2 = as.numeric(train$Z2[1:(dim(train)[1] - k)])
z3 = as.numeric(train$Z3[1:(dim(train)[1] - k)])
z5 = as.numeric(train$Z5[1:(dim(train)[1] - k)])
y = as.numeric(train$Y[-1:-5])
lm1 = lm(y ~ x13 + x16 + x18 + x19 + x39 + z2 + z3 + z5)
summary(lm1)
lm2 = lm(y ~ x13 + x16 + x18 + x39 + z3)
summary(lm2)
newdata = as.data.frame(coredata((test[,-9])))
names(newdata) = c("x13", "x16", "x18", "x19", "x39", "z2", "z3", "z5")
# newdata = newdata[, c(1,2,3,5,7)]
pred = predict.lm(lm1, newdata = newdata)
plot(as.numeric(test$Y), type = "l")
lines(pred[(k+1):length(pred)], type = "l", col = "red")
head(test)
l13 = lm(y ~ x13)
summary(l13)
newdata = as.data.frame(coredata((test$X13)))
names(newdata) = c("x13")
pred = predict.lm(l13, newdata = newdata)
plot(as.numeric(test$Y), type = "l")
lines(pred[(k+1):length(pred)], type = "l", col = "red")
plot(pred[(k+1):length(pred)], type = "l", col = "red")
lines(as.numeric(test$Y), type = "l")
###
l16 = lm(y ~ x16)
summary(l16)
newdata = as.data.frame(coredata((test$X16)))
names(newdata) = c("x16")
pred = predict.lm(l16, newdata = newdata)
lines(as.numeric(test$Y), type = "l")
plot(pred[(k+1):length(pred)], type = "l", col = "red")
lines(as.numeric(test$Y), type = "l")
plot(as.numeric(test$Y), type = "l")
lines(pred[(k+1):length(pred)], type = "l", col = "red")
l18 = lm(y ~ x18)
summary(l18)
newdata = as.data.frame(coredata((test$X18)))
names(newdata) = c("x18")
pred = predict.lm(l18, newdata = newdata)
plot(as.numeric(test$Y), type = "l")
lines(pred[(k+1):length(pred)], type = "l", col = "red")
plot(pred[(k+1):length(pred)], type = "l", col = "red")
lines(as.numeric(test$Y), type = "l")
l19 = lm(y ~ x19)
summary(l19)
newdata = as.data.frame(coredata((test$X19)))
names(newdata) = c("x19")
pred = predict.lm(l19, newdata = newdata)
plot(as.numeric(test$Y), type = "l")
lines(pred[(k+1):length(pred)], type = "l", col = "red")
plot(pred[(k+1):length(pred)], type = "l", col = "red")
lines(as.numeric(test$Y), type = "l")
l39 = lm(y ~ x39)
summary(l16)
newdata = as.data.frame(coredata((test$X39)))
names(newdata) = c("x39")
pred = predict.lm(l39, newdata = newdata)
plot(as.numeric(test$Y), type = "l")
lines(pred[(k+1):length(pred)], type = "l", col = "red")
z2 = lm(y ~ z2)
summary(z2)
newdata = as.data.frame(coredata((test$z2)))
names(newdata) = c("z2")
pred = predict.lm(z2, newdata = newdata)
plot(as.numeric(test$Y), type = "l")
lines(pred[(k+1):length(pred)], type = "l", col = "red")
z2 = lm(y ~ z2)
summary(z2)
z2 = lm(y ~ z2)
z2 = as.numeric(train$Z2[1:(dim(train)[1] - k)])
z2 = lm(y ~ z2)
summary(z2)
newdata = as.data.frame(coredata((test$Z2)))
names(newdata) = c("z2")
pred = predict.lm(z2, newdata = newdata)
plot(as.numeric(test$Y), type = "l")
lines(pred[(k+1):length(pred)], type = "l", col = "red")
z2 = as.numeric(train$Z2[1:(dim(train)[1] - k)])
z3 = as.numeric(train$Z3[1:(dim(train)[1] - k)])
z5 = as.numeric(train$Z5[1:(dim(train)[1] - k)])
y = as.numeric(train$Y[-1:-5])
z2 = lm(y ~ z2)
summary(z2)
newdata = as.data.frame(coredata((test$Z2)))
names(newdata) = c("z2")
pred = predict.lm(z2, newdata = newdata)
plot(as.numeric(test$Y), type = "l")
lines(pred[(k+1):length(pred)], type = "l", col = "red")
z3 = lm(y ~ z3)
summary(l16)
names(newdata) = c("z3")
pred = predict.lm(z3, newdata = newdata)
plot(as.numeric(test$Y), type = "l")
lines(pred[(k+1):length(pred)], type = "l", col = "red")
z3 = lm(y ~ z3)
summary(z3)
lz3 = lm(y ~ z3)
summary(lz3)
z3 = as.numeric(train$Z3[1:(dim(train)[1] - k)])
z3 = as.numeric(train$Z3[1:(dim(train)[1] - k)])
z2 = as.numeric(train$Z2[1:(dim(train)[1] - k)])
lz2 = lm(y ~ z2)
summary(lz2)
newdata = as.data.frame(coredata((test$Z2)))
names(newdata) = c("z2")
pred = predict.lm(lz2, newdata = newdata)
plot(as.numeric(test$Y), type = "l")
lines(pred[(k+1):length(pred)], type = "l", col = "red")
###
lz3 = lm(y ~ z3)
summary(lz3)
newdata = as.data.frame(coredata((test$Z3)))
names(newdata) = c("z3")
pred = predict.lm(z3, newdata = newdata)
plot(as.numeric(test$Y), type = "l")
pred = predict.lm(z3, newdata = newdata)
pred = predict.lm(lz3, newdata = newdata)
plot(as.numeric(test$Y), type = "l")
lines(pred[(k+1):length(pred)], type = "l", col = "red")
lz3 = lm(y ~ z3)
summary(lz3)
lz5 = lm(y ~ z5)
summary(lz5)
newdata = as.data.frame(coredata((test$Z5)))
names(newdata) = c("z5")
pred = predict.lm(lz5, newdata = newdata)
plot(as.numeric(test$Y), type = "l")
lines(pred[(k+1):length(pred)], type = "l", col = "red")
##### Initialisation #####
setwd("~/CMF/Courses/Applied Financial Econometrics/4. Low loss VaR curves using GARCH/Homework 4")
library(quantmod)
library(ggplot2)
library(ghyp)
library(FinTS)
library(copula)
library(fGarch)
library(tseries)
Sys.setlocale("LC_ALL","English")
##### Loading data #####
tickers = c("SPY","DIA") # specify the tickers to load
e <- new.env() # environment where data will be stored
options("getSymbols.warning4.0"=FALSE) # suppress warning about future change in the function behaviour
getSymbols(tickers, src = "google", from="2014-01-01", env=e) # load data from Yahoo Finance
data = do.call(merge, eapply(e, Cl)[tickers]) # merge data into a single xts taking only adjusted prices
names(data) = tickers
##### Calculate returns #####
rets = apply(data, 2, function(x) diff(x)/x[-length(x)])
rets = xts(rets, order.by = index(data)[-1])
##### LM-test #####
ArchTest(rets$SPY,lags=12)
ArchTest(rets$DIA,lags=12)
##### GARCH modelling #####
#SPY
SPY.gfit <- garchFit(formula=~aparch(1,1),data=rets$SPY,delta=2,
include.delta=FALSE,leverage=TRUE,cond.dist="sged",
shape=1.2,include.shape=TRUE,trace=FALSE)
plot(SPY.gfit,which=13)
plot(SPY.gfit,which=10)
#DIA
DIA.gfit <- garchFit(formula=~aparch(1,1),data=rets$DIA,delta=2,
include.delta=FALSE,leverage=TRUE,cond.dist="sged",
shape=1.2,include.shape=TRUE,trace=FALSE)
plot(DIA.gfit,which=13)
plot(DIA.gfit,which=10)
##### Stationarity tests #####
adf.test(rets$SPY)
adf.test(rets$DIA)
pp.test(rets$SPY)
pp.test(rets$DIA)
kpss.test(rets$SPY, null="Level")
kpss.test(rets$DIA, null="Level")
##### Standardized residuals #####
z <- matrix(nrow=length(rets$SPY),ncol=2)
z[,1] <- SPY.gfit@residuals / SPY.gfit@sigma.t
z[,2] <- DIA.gfit@residuals / DIA.gfit@sigma.t
##### Residuals partial distributions #####
mean <- c(0,0); sd <- c(1,1); nu <- c(1.2,1.2)
xi <- c(SPY.gfit@fit$par["skew"], DIA.gfit@fit$par["skew"])
cdf <- matrix(nrow=length(rets$SPY),ncol=2)
for (i in 1:2) cdf[,i] = psged(z[,i],mean=mean[i],sd=sd[i],nu=nu[i],xi=xi[i])
##### Initialise copulas #####
norm.cop <- normalCopula(dim=2,param=0.5,dispstr="un")
stud.cop <- tCopula(dim=2,param=0.5,df=5,df.fixed=TRUE,dispstr="un")
gumb.cop <- gumbelCopula(dim=2,param=2)
clay.cop <- claytonCopula(dim=2,param=2)
##### Fit copulas #####
norm.fit <- fitCopula(cdf,copula=norm.cop)
stud.fit <- fitCopula(cdf,copula=stud.cop)
gumb.fit <- fitCopula(cdf,copula=gumb.cop)
clay.fit <- fitCopula(cdf,copula=clay.cop)
##### Monte-Carlo #####
N = 100000
cdf.sim <- rcopula(n=N,copula=stud.fit@copula)
z.sim <- matrix(nrow=N,ncol=2)
for (i in 1:2) z.sim[,i] <- qsged(cdf.sim[,i],
mean=mean[i],sd=sd[i],nu=nu[i],xi=xi[i])
frc1 <- predict(SPY.gfit,n.ahead=1)
frc2 <- predict(DIA.gfit,n.ahead=1)
mu <- c(frc1[,1],frc2[,1])
sigma <- c(frc1[,3],frc2[,3])
##### Modelled portfolio returns #####
w = c(0.5, 0,5)
prt.sim <- w[1]*(mu[1]+sigma[1]*z.sim[,1]) +
w[2]*(mu[2]+sigma[2]*z.sim[,2])
##### VaR and ES #####
alpha <- 0.10
prt.sim <- sort(prt.sim)
VaR <- prt.sim[alpha*N]
ES <- mean(prt.sim[1:(alpha*N-1)])
##### Calculate VaR curve #####
VaR_curve <- numeric()
h <- 0.5 * 260 # window length
for (i in (h+1):length(rets[,1]))
{
h.rets <- rets[(i-h):(i-1),]
SPY.gfit <- garchFit(formula=~aparch(1,1),data=h.rets$SPY,delta=2,
include.delta=FALSE,leverage=TRUE,cond.dist="sged",
shape=1.2,include.shape=TRUE,trace=FALSE)
DIA.gfit <- garchFit(formula=~aparch(1,1),data=h.rets$DIA,delta=2,
include.delta=FALSE,leverage=TRUE,cond.dist="sged",
shape=1.2,include.shape=TRUE,trace=FALSE)
z <- matrix(nrow=length(h.rets$SPY),ncol=2)
z[,1] <- SPY.gfit@residuals / SPY.gfit@sigma.t
z[,2] <- DIA.gfit@residuals / DIA.gfit@sigma.t
mean <- c(0,0); sd <- c(1,1); nu <- c(1.2,1.2)
xi <- c(SPY.gfit@fit$par["skew"], DIA.gfit@fit$par["skew"])
cdf <- matrix(nrow=length(h.rets$SPY),ncol=2)
for (j in 1:2) cdf[,j] = psged(z[,j],mean=mean[j],sd=sd[j],nu=nu[j],xi=xi[j])
stud.fit <- fitCopula(cdf,copula=stud.cop)
N = 100000
cdf.sim <- rcopula(n=N,copula=stud.fit@copula)
z.sim <- matrix(nrow=N,ncol=2)
for (j in 1:2) z.sim[,j] <- qsged(cdf.sim[,j],
mean=mean[j],sd=sd[j],nu=nu[j],xi=xi[j])
frc1 <- predict(SPY.gfit,n.ahead=1)
frc2 <- predict(DIA.gfit,n.ahead=1)
h.mu <- c(frc1[,1],frc2[,1])
h.sigma <- c(frc1[,3],frc2[,3])
h.prt.sim <- w[1]*(h.mu[1]+h.sigma[1]*z.sim[,1]) +
w[2]*(h.mu[2]+h.sigma[2]*z.sim[,2])
h.prt.sim <- sort(prt.sim)
VaR_curve[i-h] <- h.prt.sim[alpha*N]
}
warnings()
##### Initialisation #####
setwd("~/CMF/Courses/Applied Financial Econometrics/4. Low loss VaR curves using GARCH/Homework 4")
library(quantmod)
library(ggplot2)
library(ghyp)
library(FinTS)
library(copula)
library(fGarch)
library(tseries)
Sys.setlocale("LC_ALL","English")
##### Loading data #####
tickers = c("SPY","DIA") # specify the tickers to load
e <- new.env() # environment where data will be stored
options("getSymbols.warning4.0"=FALSE) # suppress warning about future change in the function behaviour
getSymbols(tickers, src = "google", from="2014-01-01", env=e) # load data from Yahoo Finance
data = do.call(merge, eapply(e, Cl)[tickers]) # merge data into a single xts taking only adjusted prices
names(data) = tickers
##### Calculate returns #####
rets = apply(data, 2, function(x) diff(x)/x[-length(x)])
rets = xts(rets, order.by = index(data)[-1])
##### LM-test #####
ArchTest(rets$SPY,lags=12)
ArchTest(rets$DIA,lags=12)
##### GARCH modelling #####
#SPY
SPY.gfit <- garchFit(formula=~aparch(1,1),data=rets$SPY,delta=2,
include.delta=FALSE,leverage=TRUE,cond.dist="sged",
shape=1.2,include.shape=TRUE,trace=FALSE)
plot(SPY.gfit,which=13)
plot(SPY.gfit,which=10)
#DIA
DIA.gfit <- garchFit(formula=~aparch(1,1),data=rets$DIA,delta=2,
include.delta=FALSE,leverage=TRUE,cond.dist="sged",
shape=1.2,include.shape=TRUE,trace=FALSE)
plot(DIA.gfit,which=13)
plot(DIA.gfit,which=10)
##### Stationarity tests #####
adf.test(rets$SPY)
adf.test(rets$DIA)
pp.test(rets$SPY)
pp.test(rets$DIA)
kpss.test(rets$SPY, null="Level")
kpss.test(rets$DIA, null="Level")
##### Standardized residuals #####
z <- matrix(nrow=length(rets$SPY),ncol=2)
z[,1] <- SPY.gfit@residuals / SPY.gfit@sigma.t
z[,2] <- DIA.gfit@residuals / DIA.gfit@sigma.t
##### Residuals partial distributions #####
mean <- c(0,0); sd <- c(1,1); nu <- c(1.2,1.2)
xi <- c(SPY.gfit@fit$par["skew"], DIA.gfit@fit$par["skew"])
cdf <- matrix(nrow=length(rets$SPY),ncol=2)
for (i in 1:2) cdf[,i] = psged(z[,i],mean=mean[i],sd=sd[i],nu=nu[i],xi=xi[i])
##### Initialise copulas #####
norm.cop <- normalCopula(dim=2,param=0.5,dispstr="un")
stud.cop <- tCopula(dim=2,param=0.5,df=5,df.fixed=TRUE,dispstr="un")
gumb.cop <- gumbelCopula(dim=2,param=2)
clay.cop <- claytonCopula(dim=2,param=2)
##### Fit copulas #####
norm.fit <- fitCopula(cdf,copula=norm.cop)
stud.fit <- fitCopula(cdf,copula=stud.cop)
gumb.fit <- fitCopula(cdf,copula=gumb.cop)
clay.fit <- fitCopula(cdf,copula=clay.cop)
##### Monte-Carlo #####
N = 100000
cdf.sim <- rcopula(n=N,copula=stud.fit@copula)
z.sim <- matrix(nrow=N,ncol=2)
for (i in 1:2) z.sim[,i] <- qsged(cdf.sim[,i],
mean=mean[i],sd=sd[i],nu=nu[i],xi=xi[i])
frc1 <- predict(SPY.gfit,n.ahead=1)
frc2 <- predict(DIA.gfit,n.ahead=1)
mu <- c(frc1[,1],frc2[,1])
sigma <- c(frc1[,3],frc2[,3])
##### Modelled portfolio returns #####
w = c(0.5, 0,5)
prt.sim <- w[1]*(mu[1]+sigma[1]*z.sim[,1]) +
w[2]*(mu[2]+sigma[2]*z.sim[,2])
##### VaR and ES #####
alpha <- 0.10
prt.sim <- sort(prt.sim)
VaR <- prt.sim[alpha*N]
ES <- mean(prt.sim[1:(alpha*N-1)])
##### Calculate VaR curve #####
VaR_curve <- numeric()
h <- 0.5 * 260 # window length
for (i in (h+1):length(rets[,1]))
{
h.rets <- rets[(i-h):(i-1),]
SPY.gfit <- garchFit(formula=~aparch(1,1),data=h.rets$SPY,delta=2,
include.delta=FALSE,leverage=TRUE,cond.dist="sged",
shape=1.2,include.shape=TRUE,trace=FALSE)
DIA.gfit <- garchFit(formula=~aparch(1,1),data=h.rets$DIA,delta=2,
include.delta=FALSE,leverage=TRUE,cond.dist="sged",
shape=1.2,include.shape=TRUE,trace=FALSE)
z <- matrix(nrow=length(h.rets$SPY),ncol=2)
z[,1] <- SPY.gfit@residuals / SPY.gfit@sigma.t
z[,2] <- DIA.gfit@residuals / DIA.gfit@sigma.t
mean <- c(0,0); sd <- c(1,1); nu <- c(1.2,1.2)
xi <- c(SPY.gfit@fit$par["skew"], DIA.gfit@fit$par["skew"])
cdf <- matrix(nrow=length(h.rets$SPY),ncol=2)
for (j in 1:2) cdf[,j] = psged(z[,j],mean=mean[j],sd=sd[j],nu=nu[j],xi=xi[j])
stud.fit <- fitCopula(cdf,copula=stud.cop)
N = 100000
cdf.sim <- rcopula(n=N,copula=stud.fit@copula)
z.sim <- matrix(nrow=N,ncol=2)
for (j in 1:2) z.sim[,j] <- qsged(cdf.sim[,j],
mean=mean[j],sd=sd[j],nu=nu[j],xi=xi[j])
frc1 <- predict(SPY.gfit,n.ahead=1)
frc2 <- predict(DIA.gfit,n.ahead=1)
h.mu <- c(frc1[,1],frc2[,1])
h.sigma <- c(frc1[,3],frc2[,3])
h.prt.sim <- w[1]*(h.mu[1]+h.sigma[1]*z.sim[,1]) +
w[2]*(h.mu[2]+h.sigma[2]*z.sim[,2])
h.prt.sim <- sort(prt.sim)
VaR_curve[i-h] <- h.prt.sim[alpha*N]
}
fact <- prt.sim[(h+1):length(prt.sim)]
plot(as.numeric(fact),type="l", ylab = "Return")
lines(VaR_curve,col="red")
alpha <- 0.10
prt.sim.sort <- sort(prt.sim)
VaR <- prt.sim.sort[alpha*N]
ES <- mean(prt.sim.sort[1:(alpha*N-1)])
w = c(0.5, 0,5)
prt.sim <- w[1]*(mu[1]+sigma[1]*z.sim[,1]) +
w[2]*(mu[2]+sigma[2]*z.sim[,2])
fact <- prt.sim[(h+1):length(prt.sim)]
plot(as.numeric(fact),type="l", ylab = "Return")
lines(VaR_curve,col="red")
alpha <- 0.10
prt.sim <- sort(prt.sim)
VaR <- prt.sim[alpha*N]
ES <- mean(prt.sim[1:(alpha*N-1)])
fact <- ret[(h+1):length(ret[,1]),1]*w[,1] + ret[(h+1):length(ret[,2]),2]*w[,2]
fact <- rets[(h+1):length(rets[,1]),1]*w[,1] + rets[(h+1):length(rets[,2]),2]*w[,2]
fact <- rets[(h+1):length(rets[,1]),1]*w[1] + rets[(h+1):length(rets[,2]),2]*w[2]
plot(as.numeric(fact),type="l", ylab = "Return")
lines(VaR_curve,col="red")
VaR_curve
##### Calculate VaR curve #####
VaR_curve <- numeric()
h <- 0.5 * 260 # window length
for (i in (h+1):length(rets[,1]))
{
h.rets <- rets[(i-h):(i-1),]
SPY.gfit <- garchFit(formula=~aparch(1,1),data=h.rets$SPY,delta=2,
include.delta=FALSE,leverage=TRUE,cond.dist="sged",
shape=1.2,include.shape=TRUE,trace=FALSE)
DIA.gfit <- garchFit(formula=~aparch(1,1),data=h.rets$DIA,delta=2,
include.delta=FALSE,leverage=TRUE,cond.dist="sged",
shape=1.2,include.shape=TRUE,trace=FALSE)
z <- matrix(nrow=length(h.rets$SPY),ncol=2)
z[,1] <- SPY.gfit@residuals / SPY.gfit@sigma.t
z[,2] <- DIA.gfit@residuals / DIA.gfit@sigma.t
mean <- c(0,0); sd <- c(1,1); nu <- c(1.2,1.2)
xi <- c(SPY.gfit@fit$par["skew"], DIA.gfit@fit$par["skew"])
cdf <- matrix(nrow=length(h.rets$SPY),ncol=2)
for (j in 1:2) cdf[,j] = psged(z[,j],mean=mean[j],sd=sd[j],nu=nu[j],xi=xi[j])
stud.fit <- fitCopula(cdf,copula=stud.cop)
N = 100000
cdf.sim <- rcopula(n=N,copula=stud.fit@copula)
z.sim <- matrix(nrow=N,ncol=2)
for (j in 1:2) z.sim[,j] <- qsged(cdf.sim[,j],
mean=mean[j],sd=sd[j],nu=nu[j],xi=xi[j])
frc1 <- predict(SPY.gfit,n.ahead=1)
frc2 <- predict(DIA.gfit,n.ahead=1)
h.mu <- c(frc1[,1],frc2[,1])
h.sigma <- c(frc1[,3],frc2[,3])
h.prt.sim <- w[1]*(h.mu[1]+h.sigma[1]*z.sim[,1]) +
w[2]*(h.mu[2]+h.sigma[2]*z.sim[,2])
h.prt.sim <- sort(h.prt.sim)
VaR_curve[i-h] <- h.prt.sim[alpha*N]
}
fact <- rets[(h+1):length(rets[,1]),1]*w[1] + rets[(h+1):length(rets[,2]),2]*w[2]
plot(as.numeric(fact),type="l", ylab = "Return")
lines(VaR_curve,col="red")
alpha
##### Kupiec test #####
K <- sum(fact<VaR_curve); alpha0 <- K/length(rets)
S <- -2*log((1-alpha)^(length(rets)-K)*alpha^K)+
2*log((1-alpha0)^(length(rets)-K)*alpha0^K)
p.value <- 1-pchisq(S,df=1)
alpha0
length(rets)
length(rets[,1])
K <- sum(fact<VaR_curve); alpha0 <- K/length(rets[,1])
S <- -2*log((1-alpha)^(length(rets[,1])-K)*alpha^K)+
2*log((1-alpha0)^(length(rets[,1])-K)*alpha0^K)
p.value <- 1-pchisq(S,df=1)
alpha0
p.value
##### LM-test #####
ArchTest(rets$SPY,lags=12)
ArchTest(rets$DIA,lags=12)
##### Stationarity tests #####
adf.test(rets$SPY)
adf.test(rets$DIA)
pp.test(rets$SPY)
pp.test(rets$DIA)
kpss.test(rets$SPY, null="Level")
kpss.test(rets$DIA, null="Level")
alpha0
p.value
